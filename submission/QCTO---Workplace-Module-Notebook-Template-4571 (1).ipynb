{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766ca1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading + clean EDA\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "csv_path = 'sample_iris.csv'\n",
    "if os.path.exists(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "else:\n",
    "    from sklearn.datasets import load_iris\n",
    "    iris = load_iris(as_frame=True)\n",
    "    df = iris.frame\n",
    "    df.columns = list(iris.feature_names) + ['target']\n",
    "\n",
    "print('Shape:', df.shape)\n",
    "display(df.head())\n",
    "print('\\nDtypes:\\n', df.dtypes)\n",
    "print('\\nSummary statistics:')\n",
    "display(df.describe(include='all'))\n",
    "print('\\nMissing values per column:')\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Histograms for numeric columns\n",
    "numeric = df.select_dtypes(include=[np.number])\n",
    "numeric.hist(figsize=(10,8))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(numeric.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation matrix')\n",
    "plt.show()\n",
    "\n",
    "# Pairplot (may take some time)\n",
    "sns.pairplot(df, vars=numeric.columns, hue='target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539396c8",
   "metadata": {},
   "source": [
    "# Capstone Project - Exploratory Data Analysis\n",
    "This notebook contains data loading, brief EDA, modeling, and report export steps. The corrupted EDA cell was removed and replaced with a clean EDA cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba80ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling: preprocessing, baseline model training, evaluation, and save\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure dataframe `df` exists (loaded by previous EDA cell)\n",
    "try:\n",
    "    df\n",
    "except NameError:\n",
    "    import os\n",
    "    if os.path.exists('sample_iris.csv'):\n",
    "        df = pd.read_csv('sample_iris.csv')\n",
    "    else:\n",
    "        from sklearn.datasets import load_iris\n",
    "        iris = load_iris(as_frame=True)\n",
    "        df = iris.frame\n",
    "        df.columns = list(iris.feature_names) + ['target']\n",
    "\n",
    "def preprocess_for_model(df_in, target_col='target', drop_thresh=0.5, max_card_onehot=10):\n",
    "    df = df_in.copy()\n",
    "    # Drop columns with too many missing values\n",
    "    drop_cols = [c for c in df.columns if df[c].isnull().mean() > drop_thresh]\n",
    "    if drop_cols:\n",
    "        print('Dropping columns with high missing rate:', drop_cols)\n",
    "        df = df.drop(columns=drop_cols)\n",
    "    # Impute numeric with median, categorical with mode\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    for c in num_cols:\n",
    "        df[c] = df[c].fillna(df[c].median())\n",
    "    for c in cat_cols:\n",
    "        mode = df[c].mode()\n",
    "        fill = mode.iloc[0] if not mode.empty else 'missing'\n",
    "        df[c] = df[c].fillna(fill)\n",
    "    # Encode categoricals: one-hot for low cardinality, label for high\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    for c in list(cat_cols):\n",
    "        if df[c].nunique() <= max_card_onehot:\n",
    "            df = pd.get_dummies(df, columns=[c], prefix=c, drop_first=True)\n",
    "        else:\n",
    "            le = LabelEncoder()\n",
    "            df[c] = le.fit_transform(df[c].astype(str))\n",
    "    return df\n",
    "\n",
    "print('Preprocessing...')\n",
    "cleaned = preprocess_for_model(df, target_col='target')\n",
    "# Prepare features and target\n",
    "if 'target' in cleaned.columns:\n",
    "    y = cleaned['target']\n",
    "    X = cleaned.drop(columns=['target'])\n",
    "else:\n",
    "    y = cleaned.iloc[:, -1]\n",
    "    X = cleaned.iloc[:, :-1]\n",
    "\n",
    "# Keep numeric features for baseline pipeline\n",
    "X_numeric = X.select_dtypes(include=[np.number]).copy()\n",
    "if X_numeric.shape[1] != X.shape[1]:\n",
    "    dropped = set(X.columns) - set(X_numeric.columns)\n",
    "    print('Dropping non-numeric columns for baseline model:', dropped)\n",
    "\n",
    "# Train/test split\n",
    "stratify = y if len(np.unique(y)) > 1 else None\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_numeric, y, test_size=0.2, random_state=42, stratify=stratify)\n",
    "\n",
    "# Fit baseline pipeline\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression(max_iter=500, multi_class='multinomial', solver='lbfgs'))\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = pipe.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Baseline model accuracy: {acc:.4f}')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix plot\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Baseline')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "model_path = 'baseline_model.pkl'\n",
    "joblib.dump(pipe, model_path)\n",
    "print(f'Saved baseline model to {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73347136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running export_results.py from notebook kernel\n",
      "Output directory: c:\\Users\\user\\Downloads\\Capstone project\n",
      "Saved confusion matrix to c:\\Users\\user\\Downloads\\Capstone project\\confusion_matrix.png\n",
      "Wrote Markdown report to c:\\Users\\user\\Downloads\\Capstone project\\results_report.md\n",
      "Wrote HTML report to c:\\Users\\user\\Downloads\\Capstone project\\results_report.html\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Run the exported script to generate Markdown and HTML reports\n",
    "print('Running export_results.py from notebook kernel')\n",
    "exec(open('export_results.py', 'r', encoding='utf-8').read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pthyon-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
